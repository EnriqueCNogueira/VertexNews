# ORQUESTRADOR PRINCIPAL - PIPELINE INTELIGENTE DE NOT√çCIAS DE MARKETING
"""
Sistema automatizado para coletar, processar, analisar e apresentar 
not√≠cias relevantes do setor de marketing digital.
Refatorado para usar banco de dados SQLite e cache em mem√≥ria
"""

from pipeline.selector import selecionar_noticias_estrategicas
from pipeline.clustering import clusterizar_noticias, interpretar_clusters
from pipeline.summarizer import sumarizar_textos
from pipeline.extractor import extrair_textos_noticias
from pipeline.collectors import coletar_noticias
from database.init_db import initialize_databases
from database.cleanup import cleanup_auxiliary_database
from database.aux_operations import get_aux_operations
from database.main_operations import get_main_operations
from database.text_cache import get_text_cache
from errors.error_handler import error_handler
import sys
import os

# Adicionar o diret√≥rio pipeline ao path
sys.path.append(os.path.join(os.path.dirname(__file__), 'pipeline'))


def executar_pipeline():
    """
    Executa o pipeline completo de processamento de not√≠cias
    usando banco de dados SQLite e cache em mem√≥ria

    Returns:
        tuple: (noticias_processadas, noticias_selecionadas)
    """
    print("="*80)
    print("           PIPELINE INTELIGENTE DE NOT√çCIAS DE MARKETING")
    print("="*80)
    print("Sistema automatizado para transformar dados brutos da web em insights estrat√©gicos")
    print("Arquitetura: SQLite + Cache em Mem√≥ria")
    print("="*80)

    try:
        # INICIALIZA√á√ÉO DOS BANCOS DE DADOS
        print("\n[INICIALIZA√á√ÉO] BANCOS DE DADOS SQLITE")
        print("-" * 50)

        if not initialize_databases():
            print("ERRO: Falha na inicializa√ß√£o dos bancos de dados.")
            return None, None

        # Obter inst√¢ncias dos gerenciadores
        aux_ops = get_aux_operations()
        main_ops = get_main_operations()
        text_cache = get_text_cache()

        # ETAPA 1: COLETA DE DADOS
        print("\n[ETAPA 1] COLETA DE DADOS")
        print("-" * 50)

        try:
            noticias_coletadas = coletar_noticias()
        except Exception as e:
            if not error_handler.handle_error(e, "Coleta de not√≠cias", continue_execution=False):
                return None, None

        if not error_handler.validate_data(noticias_coletadas, 'not_empty', "Coleta de not√≠cias"):
            print("ERRO: Nenhuma not√≠cia foi coletada. Verificando conectividade...")
            return None, None

        print(
            f"SUCESSO: {len(noticias_coletadas)} not√≠cias coletadas de todas as fontes")

        # Verificar estat√≠sticas do banco auxiliar
        counts = aux_ops.count_news()
        print(
            f"üìä Banco auxiliar: {counts['total']} not√≠cias, {counts['com_resumos']} com resumos")

        # ETAPA 2: EXTRA√á√ÉO DE TEXTO
        print("\n[ETAPA 2] EXTRA√á√ÉO DE TEXTO")
        print("-" * 50)

        try:
            textos_para_sumarizar, indices_validos, stats = extrair_textos_noticias()
        except Exception as e:
            error_handler.handle_error(e, "Extra√ß√£o de textos")
            return None, None

        if not error_handler.validate_data(textos_para_sumarizar, 'not_empty', "Extra√ß√£o de textos"):
            print("ERRO: Nenhum texto foi extra√≠do com sucesso.")
            return None, None

        # Verificar estat√≠sticas do cache
        cache_stats = text_cache.get_cache_stats()
        print(
            f"üìä Cache em mem√≥ria: {cache_stats['total_texts']} textos armazenados")

        # ETAPA 3: SUMARIZA√á√ÉO
        print("\n[ETAPA 3] SUMARIZA√á√ÉO COM IA")
        print("-" * 50)

        try:
            textos_sumarizados = sumarizar_textos()
        except Exception as e:
            error_handler.handle_error(e, "Sumariza√ß√£o com IA")
            return None, None

        if textos_sumarizados == 0:
            print("ERRO: Falha na sumariza√ß√£o dos textos.")
            return None, None

        print(f"‚úÖ {textos_sumarizados} textos sumarizados com sucesso")

        # ETAPA 4: CLUSTERIZA√á√ÉO
        print("\n[ETAPA 4] CLUSTERIZA√á√ÉO E AN√ÅLISE")
        print("-" * 50)

        try:
            kmeans, vectorizer, noticias_processadas = clusterizar_noticias()
        except Exception as e:
            error_handler.handle_error(e, "Clusteriza√ß√£o")
            return None, None

        if kmeans is None:
            print("ERRO: Falha na clusteriza√ß√£o.")
            return None, None

        # ETAPA 5: INTERPRETA√á√ÉO DOS CLUSTERS
        print("\n[ETAPA 5] INTERPRETA√á√ÉO DOS CLUSTERS")
        print("-" * 50)

        try:
            noticias_finais = interpretar_clusters(kmeans, vectorizer)
        except Exception as e:
            error_handler.handle_error(e, "Interpreta√ß√£o de clusters")
            # Continua execu√ß√£o mesmo com erro nesta etapa

        # ETAPA 6: SELE√á√ÉO ESTRAT√âGICA
        print("\n[ETAPA 6] SELE√á√ÉO ESTRAT√âGICA")
        print("-" * 50)

        try:
            noticias_selecionadas = selecionar_noticias_estrategicas(top_n=15)
        except Exception as e:
            error_handler.handle_error(e, "Sele√ß√£o estrat√©gica")
            noticias_selecionadas = []

        # ETAPA 7: LIMPEZA
        print("\n[ETAPA 7] LIMPEZA DO BANCO AUXILIAR")
        print("-" * 50)

        try:
            cleanup_success = cleanup_auxiliary_database()
            if cleanup_success:
                print("‚úÖ Banco auxiliar limpo e removido com sucesso")
            else:
                print("‚ö†Ô∏è Alguns problemas na limpeza do banco auxiliar")
        except Exception as e:
            error_handler.handle_error(e, "Limpeza do banco auxiliar")

        # RESULTADO FINAL
        print("\n" + "="*80)
        print("           PIPELINE EXECUTADO COM SUCESSO!")
        print("="*80)

        # Estat√≠sticas finais
        main_stats = main_ops.get_statistics()
        print(
            f"Total de not√≠cias no banco principal: {main_stats.get('total', 0)}")
        print(
            f"Not√≠cias selecionadas nesta execu√ß√£o: {len(noticias_selecionadas)}")
        print(
            f"Not√≠cias dos √∫ltimos 7 dias: {main_stats.get('ultimos_7_dias', 0)}")

        # Resumo de erros e avisos
        error_summary = error_handler.get_summary()
        if error_summary['errors'] > 0 or error_summary['warnings'] > 0:
            print(f"\nRESUMO DE PROBLEMAS ENCONTRADOS:")
            print(f"   - Erros encontrados: {error_summary['errors']}")
            print(f"   - Avisos gerados: {error_summary['warnings']}")
            print(f"   - Log salvo em: pipeline_errors.log")

        print("="*80)

        return noticias_coletadas, noticias_selecionadas

    except Exception as e:
        error_handler.handle_error(
            e, "Pipeline principal", continue_execution=False)
        print("ERRO CR√çTICO: Pipeline interrompido.")
        print("Verifique a conectividade com a internet e as depend√™ncias instaladas.")
        return None, None


def main():
    """Fun√ß√£o principal do orquestrador"""
    print("Iniciando Pipeline Inteligente de Not√≠cias de Marketing...")
    print("Nova arquitetura: SQLite + Cache em Mem√≥ria")

    # Executar pipeline
    noticias_coletadas, noticias_selecionadas = executar_pipeline()

    if noticias_coletadas is not None:
        print("\nRESUMO FINAL:")
        print(f"   - Not√≠cias coletadas: {len(noticias_coletadas)}")
        if noticias_selecionadas:
            print(f"   - Insights estrat√©gicos: {len(noticias_selecionadas)}")
            print(
                "\nAs 15 not√≠cias mais estrat√©gicas foram selecionadas e salvas no banco principal!")
            print("Dados prontos para consumo pela API do site.")
        else:
            print("   - Insights estrat√©gicos: N√£o dispon√≠veis")
    else:
        print("\nPipeline n√£o p√¥de ser executado completamente.")

    print("\nExecu√ß√£o finalizada.")


if __name__ == "__main__":
    main()
